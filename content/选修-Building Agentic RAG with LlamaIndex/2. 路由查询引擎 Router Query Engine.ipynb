{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86b3a54b-a129-4b45-a840-06017ecf44a9",
   "metadata": {},
   "source": [
    "# 第二章 路由查询引擎 Router Query Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f807277a-77e0-40d9-bf45-0c10809c65aa",
   "metadata": {},
   "source": [
    "## 一、引言"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df165de2-d1a9-46d8-8395-4f3cf0e29226",
   "metadata": {
    "tags": []
   },
   "source": [
    "在本章节中，我们将学习最简单形式的<strong>代理式检索增强生成(Agentic RAG)</strong>。给定一个<strong>查询(Query)</strong>，<strong>路由器(Router)</strong>通过理解查询，从几个<strong>查询引擎(Query Engine)</strong>中的选择一个来执行查询。\n",
    "\n",
    "我们将构建一个简单的路由器，该路由器可以处理<strong>单个文档的问答和摘要</strong>。 \n",
    "\n",
    "\n",
    "<pre style=\"color: blue;\">\n",
    "                               +---------------------------------+\n",
    "                               |                                 |\n",
    "                               | Input: What is the summary of   |\n",
    "                               | the MetaGPT document?           |\n",
    "                               +---------------+-----------------+\n",
    " <pre style=\"color: green;\"> \n",
    "                                               |   \n",
    "                        +----------------------+--------------------+\n",
    "                        |                                           |\n",
    "                        |                路由查询引擎                 |\n",
    "                        |              Router Engine                |\n",
    "                        +-------+-----------------------------------+\n",
    "                                |\n",
    "            +-------------------+-------------------+\n",
    "            |                                       |\n",
    "    +-------+-------+                       +-------+-------+\n",
    "    |               |                       |               |\n",
    "    |  问答查询引擎   |                       |  摘要查询引擎   |\n",
    "    |               |                       |               |\n",
    "    | Query Engine  |                       | Query Engine  |\n",
    "    |     (QA)      |                       |(Summarization)|\n",
    "    |               |                       |               |\n",
    "    +-------+-------+                       +-------+-------+\n",
    "            |                                       |\n",
    "    +-------+-------+                       +-------+-------+\n",
    "    |               |                       |               |\n",
    "    |  Vector Index |                       | Summary Index |\n",
    "    |               |                       |               |\n",
    "    +---------------+                       +-------+-------+\n",
    "                                                    |\n",
    "                                                    \n",
    "<pre style=\"color: blue;\">\n",
    "                                        +-----------+------------+\n",
    "                                        |                         |\n",
    "                                        | Output: Summary of      |\n",
    "                                        | the MetaGPT document    |\n",
    "                                        +-------------------------+\n",
    "\n",
    "\n",
    "\n",
    "<!-- </pre> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc96ecdb-88bd-42ef-9cfe-cdcaab97e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from dotenv import find_dotenv\n",
    "\n",
    "# 你需要在文件目录下创建一个.env的文件，文件中存放你的 OPENAI_API_KEY=“your OPENAI API Key”\n",
    "# 从 .env 文件将 OPENAI_API_KEY 加载为环境变量。\n",
    "# 当后续使用到 OPENAI 模型时，环境变量会直接被使用于认证(Authentication)。\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fe2ee0-445d-4b9e-b707-8808f5d4dbea",
   "metadata": {},
   "source": [
    "因为 OPENAI_API_KEY 已经被加载为环境变量，所以你通过一下方式去查看 OPENAI_API_KEY 这个环境变量。\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.getenv(\"OPENAI_API_KEY\")\n",
    "```\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7479debd-eb95-435f-af5d-f385acd48f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fed284-00d5-4930-a9f1-8067150c5651",
   "metadata": {},
   "source": [
    "LlamaIndex 为了实现高效加载和处理数据，有些功能使用了asyncio实现异步编程优化 I/O 操作。然而，asyncio 的设计本身不支持事件循环的嵌套使用，这意味着在已经运行事件循环的环境中，尝试再次启动事件循环或同步运行任务会导致异常，通常会抛出 \"RuntimeError: This event loop is already running\" 错误。 在Jupyter Notebook这样的交互式环境中，因为每个代码单元格（cell）都可能尝试创建或操作事件循环。从而出现事件循环的嵌套使用。\n",
    "\n",
    "为了解决这个问题，nest_asyncio 模块对 asyncio 进行了补丁，允许嵌套使用 asyncio 的函数，例如 asyncio.run() 和 loop.run_until_complete()。这种补丁修改了 asyncio 的行为，临时允许 asyncio 在已有事件循环的环境中正常工作，确保在 Jupyter Notebook 环境中，即使存在已运行的事件循环，也能够正确执行异步任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e9e5b-b03a-4cb8-a884-a17f28058307",
   "metadata": {},
   "source": [
    "## 二、加载数据\n",
    "\n",
    "这里需要用到的文档为`metagpt.pdf`。已经在当前目录下面。 或者你也可以通过下面的指令来下载文件。\n",
    "\n",
    "```bash\n",
    "!wget \"https://openreview.net/pdf?id=VtmBAGCN7o\" -O metagpt.pdf\n",
    "```\n",
    "\n",
    "`wget` 为linux系统下的下载指令。如果你的系统为Windows或者Mac, 则可以通过curl来下载。\n",
    "\n",
    "```bash\n",
    "!curl -s -o metagpt.pdf \"https://openreview.net/pdf?id=VtmBAGCN7o\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6771279a-31c2-4ce6-be8e-9e5e44b9ec55",
   "metadata": {},
   "source": [
    "### 2.1 加载数据为文档格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad843f0a-70f0-4684-8f4b-93b5a5b3f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"data/metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b216a9b7-9d53-4637-9ff1-64758b8aa008",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddc28ca3-51bf-46ae-8a37-aa9f4c1afea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7acd26-4e68-43dd-857b-7790dc4a1fab",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "数据加载后的为格式为列表(`List`)。这里包含列表中共有29个元素。\n",
    "\n",
    "我们来看看元素的类型。\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7a9d14-b62e-4ebb-bbe0-bb2dba19b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.Document"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bf2e2-6a3e-4482-bf53-bcd8460e008e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "元素的类型为llama_index自定义文档类型(`llama_index.core.schema.Document`)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715028c0-b721-4075-9351-a562940d5683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator', 'class_name'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdb3c5-9706-4035-84fe-3459b0056fb5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "将llama_index自定义文档类型转为为字典类型（`dictionary`），并输出其中的键(`keys`)。可以看到对于每个文档，包含的信息。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7caeee2-25b1-4fb2-8c3e-498e387bbe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "文档的Token个数\n",
      "------------------------------------\n",
      "[881, 667, 1088, 562, 337, 859, 1050, 528, 816, 1052, 1128, 1080, 993, 355, 904, 155, 591, 313, 419, 248, 238, 472, 540, 878, 867, 304, 53, 550, 813]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer()\n",
    "print(\"------------------------------------\")\n",
    "print(\"文档的Token个数\")\n",
    "print(\"------------------------------------\")\n",
    "print([len(tokenizer(documents[i].text)) for i in range(len(documents))])\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0043c117-f681-421d-a177-846584c446cd",
   "metadata": {},
   "source": [
    "### 2.2 切割文档为节点格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d93fe406-0988-498e-9db0-7bfe1d3c772a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a81d694-43aa-422a-9b74-425183d25133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff54c1f1-fb1b-4d5c-bc7f-38476c45a0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.schema.TextNode"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nodes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d68ba392-0f33-4036-aaca-b9439c053348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id_', 'embedding', 'metadata', 'excluded_embed_metadata_keys', 'excluded_llm_metadata_keys', 'relationships', 'text', 'start_char_idx', 'end_char_idx', 'text_template', 'metadata_template', 'metadata_seperator', 'class_name'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e0c41e-34be-47f5-a75e-adca73a63c85",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "将llama_index自定义文档类型documents, 进行进一步切分为llama_index自定义节点类型(llama_index.core.schema.TextNode)。每个文档的Token个数少于等于1024个。 切分之后由29个文档变为34个节点。\n",
    " \n",
    "同时可以看到节点的元数据, 和文档的元数据一样。\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95af8e8f-69b5-4b21-8879-863c60f530f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "节点的Token个数\n",
      "------------------------------------\n",
      "[881, 667, 968, 304, 562, 337, 859, 988, 87, 528, 816, 761, 478, 955, 360, 966, 278, 993, 355, 904, 155, 591, 313, 419, 248, 238, 472, 540, 878, 867, 304, 53, 550, 813]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "第三个文档被分隔为两个节点,紫色+绿色为第一个节点，绿色+蓝色为第二个节点。\n",
      "也就是说，绿色的部分同时在两个节点中。即两个节点存在交叉(Overlap)\n",
      "----------------------------------------------------------------\n",
      "\u001b[95mPreprint\n",
      "•We introduce MetaGPT, a meta-programming framework for multi-agent collaboration based on\n",
      "LLMs. It is highly convenient and flexible, with well-defined functions like role definition and\n",
      "message sharing, making it a useful platform for developing LLM-based multi-agent systems.\n",
      "•Our innovative integration of human-like SOPs throughout MetaGPT’s design significantly en-\n",
      "hances its robustness, reducing unproductive collaboration among LLM-based agents. Furthermore,\n",
      "we introduce a novel executive feedback mechanism that debugs and executes code during runtime,\n",
      "significantly elevating code generation quality (e.g., 5.4% absolute improvement on MBPP).\n",
      "•We achieve state-of-the-art performance on HumanEval (Chen et al., 2021a) and MBPP (Austin\n",
      "et al., 2021). Extensive results convincingly validate MetaGPT, suggesting that it is a promising\n",
      "meta-programming framework for developing LLM-based multi-agent systems.\n",
      "2 R ELATED WORK\n",
      "Automatic Programming The roots of automatic programming reach back deep into the previ-\n",
      "ous century. In 1969, Waldinger & Lee (1969) introduced “PROW,” a system designed to accept\n",
      "program specifications written in predicate calculus, generate algorithms, and create LISP imple-\n",
      "mentations (McCarthy, 1978). Balzer (1985) and Soloway (1986) made efforts to advance auto-\n",
      "matic programming and identified potential methods to achieve it. Recent approaches use natural\n",
      "language processing (NLP) techniques (Ni et al., 2023; Skreta et al., 2023; Feng et al., 2020; Li\n",
      "et al., 2022; Chen et al., 2018; 2021b; Zhang et al., 2023). Automatic programming has grown into\n",
      "an industry delivering paid functions such as Microsoft Copilot. Lately, LLMs-based agents (Yao\n",
      "et al., 2022; Shinn et al., 2023; Lin et al., 2023) have advanced automatic programming develop-\n",
      "ment. Among them, ReAct (Yao et al., 2022) and Reflexion (Shinn et al., 2023) utilize a chain of\n",
      "thought prompts (Wei et al., 2022) to generate reasoning trajectories and action plans with LLMs.\n",
      "Both works demonstrate the effectiveness of the ReAct style loop of reasoning as a design paradigm\n",
      "for empowering automatic programming. Additionally, ToolFormer (Schick et al., 2023) can learn\n",
      "how to use external tools through simple APIs. The research most closely aligned with our work\n",
      "by Li et al. (2023) proposes a straightforward role-play framework for programming that involves\n",
      "communication between agents playing different roles. Qian et al. (2023) utilizes multiple agents for\n",
      "software development. Although existing papers (Li et al., 2023; Qian et al., 2023) have improved\n",
      "productivity, they have not fully tapped into effective workflows with structured output formats.\n",
      "This makes it harder to deal with complex software engineering issues.\n",
      "LLM-Based Multi-Agent Frameworks Recently, LLM-based autonomous agents have gained\n",
      "tremendous interest in both industry and academia (Wang et al., 2023b). Many works (Chen et al.,\n",
      "2024; Wang et al., 2023c; Du et al., 2023; Zhuge et al., 2023; Hao et al., 2023; Akata et al., 2023)\n",
      "have improved the problem-solving abilities of LLMs by integrating discussions among multiple\n",
      "agents. Stable-Alignment (Liu et al., 2023) creates instruction datasets by deriving consensus on\n",
      "value judgments through interactions across a sandbox with LLM agents. \u001b[0m\u001b[92mOther works focus on\n",
      "sociological phenomena. For example, Generative Agents (Park et al., 2023) creates a “town” of 25\n",
      "agents to study language interaction, social understanding, and collective memory. In the Natural\n",
      "Language-Based Society of Mind (NLSOM) (Zhuge et al., 2023), agents with different functions\n",
      "interact to solve complex tasks through multiple rounds of “mindstorms.” Cai et al. (2023) propose\n",
      "a model for cost reduction by combining large models as tool makers and small models as tool users.\n",
      "Some works emphasize cooperation and competition related to planning and strategy (Bakhtin et al.,\n",
      "2022); others propose LLM-based economies (Zhuge et al., 2023). These works focus on open-\n",
      "world human behavior simulation, while MetaGPT aims to introduce human practice into multi-\n",
      "agents frameworks.\u001b[0m\u001b[94m Besides, LLM-based agents face the challenges of “assistant repeated instruc-\n",
      "tion” or “infinite loop of message” (Talebirad & Nadiri, 2023; Li et al., 2023). These challenges\n",
      "become more urgent in task-oriented collaborations, which require consistent and mutually benefi-\n",
      "cial interactions (Elazar et al., 2021; Wang et al., 2022; Jiang et al., 2023). This motivates our focus\n",
      "on applying advanced concepts such as Standard Operating Procedures in software development to\n",
      "multi-agent frameworks.\n",
      "3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------\")\n",
    "print(\"节点的Token个数\")\n",
    "print(\"------------------------------------\")\n",
    "print([len(tokenizer(nodes[i].text)) for i in range(len(nodes))])\n",
    "print()\n",
    "print(\"----------------------------------------------------------------\")\n",
    "print(\"第三个文档被分隔为两个节点,紫色+绿色为第一个节点，绿色+蓝色为第二个节点。\")\n",
    "print(\"也就是说，绿色的部分同时在两个节点中。即两个节点存在交叉(Overlap)\")\n",
    "print(\"----------------------------------------------------------------\")\n",
    "from src.tool import highlight_doc\n",
    "\n",
    "highlight_doc(doc = documents[2].text, \n",
    "              splited_node1=nodes[2].text, \n",
    "              splited_node2=nodes[3].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd13104-a2c9-4957-bb9c-b3c5c56468e5",
   "metadata": {},
   "source": [
    "## 三、定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81e4d92b-9f88-4edc-af6f-2193df91bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd69eb9-77e3-4b3d-8b2b-bad1afdffa42",
   "metadata": {},
   "source": [
    "## 四、创建摘要索引和向量索引"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e0a23-db84-4544-b432-3e5bd8171913",
   "metadata": {},
   "source": [
    "基于前面加载并切割得到的文档节点(nodes)来创建摘要索引和向量索引。 在创建摘要索引和向量索引时会调用到嵌入模型(embed_model)。因为这里的模型为OpenAIEmbedding，课程开始加载的环境变量OPENAI_API_KEY会被用于认证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7037ea6-f763-4b45-98d9-f0de8f9059f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex, VectorStoreIndex\n",
    "\n",
    "summary_index = SummaryIndex(nodes)\n",
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df0534-1da7-4cb9-b004-4b4bf4ab02d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 五、定义查询引擎\n",
    "\n",
    "基于索引构建摘要相应的查询引擎, 并通过设置相应的元数据(Meta Data)构建查询引擎工具。\n",
    "\n",
    "元数据为对于引擎工具的描述(description)。这些描述会被路由引擎用于为特定查询(Query)选择最合适的查询引擎。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e5339b6-5bb7-4164-be54-766833d899c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "# 基于摘要索引summary_index构建摘要查询引擎\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\",\n",
    "    use_async=True,\n",
    ")\n",
    "\n",
    "# 基于向量索引vector_index构建向量查询引擎\n",
    "vector_query_engine = vector_index.as_query_engine()\n",
    "\n",
    "\n",
    "# 设置置相应的元数据(Meta Data)， 构建摘要查询引擎工具。\n",
    "# 摘要查询工具用于回答与 MetaGPT 相关的摘要问题查询\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=summary_query_engine,\n",
    "    description=(\n",
    "        \"Useful for summarization questions related to MetaGPT\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 设置置相应的元数据(Meta Data)，构建向量查询引擎工具。\n",
    "# 向量查询引擎工具用于回答与 MetaGPT 相关的问答\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=vector_query_engine,\n",
    "    description=(\n",
    "        \"Useful for retrieving specific context from the MetaGPT paper.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671422b6-ae19-4ee8-b529-dc98f7991b1f",
   "metadata": {},
   "source": [
    "## 五、定义路由查询引擎\n",
    "\n",
    "路由查询引擎从多个候选查询引擎中选择一个来执行查询。\n",
    "- 选择器(selector): 根据每个候选查询的元数据和查询选择一个选项的选择器。\n",
    "- 候选查询引擎工具（query_engine_tools）: 一系列候选查询引擎。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7aff27c9-ed19-4108-ac9a-6b9f2078d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine.router_query_engine import RouterQueryEngine\n",
    "from llama_index.core.selectors import LLMSingleSelector\n",
    "\n",
    "\n",
    "query_engine = RouterQueryEngine(\n",
    "    selector=LLMSingleSelector.from_defaults(),\n",
    "    query_engine_tools=[\n",
    "        summary_tool,\n",
    "        vector_tool,\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea65451-29aa-4a8a-a2a2-92706efc7c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mThe document introduces MetaGPT, a meta-programming framework that utilizes Standardized Operating Procedures (SOPs) to enhance the problem-solving capabilities of multi-agent systems based on Large Language Models (LLMs). MetaGPT assigns specific roles to agents, streamlines workflows, and improves task decomposition. It models agents as a simulated software company, emphasizing role specialization, workflow management, and efficient sharing mechanisms. The framework incorporates an executable feedback mechanism to enhance code generation quality during runtime and has demonstrated state-of-the-art performance in various benchmarks. The document also discusses the development process for software projects using MetaGPT, highlighting the structured workflow involving different team members and the successful generation of functional applications. Additionally, it addresses the performance of different GPT models in benchmarks, ethical concerns, and the benefits of MetaGPT in enabling natural language programming and improving transparency and data security.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What is the summary of the document?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e66cbed-6f0b-4d40-b454-b26736a7e41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "print(len(response.source_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c963f2-a92b-425b-b32c-37d68311b2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: Useful for summarization questions related to MetaGPT.\n",
      "\u001b[0mAgents share information with other agents by utilizing shared message pools, subscribing to relevant messages based on their profiles, reviewing previous feedback to make necessary adjustments, generating and exchanging various documents and artifacts, and utilizing mechanisms such as message pools and subscriptions within the workflow management framework. These methods facilitate efficient communication and collaboration within the multi-agent system, ensuring that information is exchanged transparently and effectively among the agents.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"How do agents share information with other agents?\"\n",
    ")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364b9e2-cf40-4e1a-9ee4-bed621287bef",
   "metadata": {},
   "source": [
    "## 六、结合起来\n",
    "我们将"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8357185d-32a0-4ade-8e52-8e286ffa04d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import get_router_query_engine\n",
    "\n",
    "query_engine = get_router_query_engine(\"data/metagpt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ce2da28-1399-4909-a7df-1da358acbd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: Ablation study results are specific context from the MetaGPT paper, making choice 2 the most relevant..\n",
      "\u001b[0mThe ablation study results demonstrate the effectiveness of MetaGPT in addressing challenges related to information overload and reducing hallucinations in software generation tasks. By utilizing a global message pool and a subscription mechanism, MetaGPT successfully manages excessive or irrelevant information, ensuring efficient communication and enhancing the relevance and utility of the information provided. This design approach is crucial in optimizing the performance of the system in handling complex software development tasks.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Tell me about the ablation study results?\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed13253c-716a-45a6-ba50-103367a42e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 0: The question is asking for a summary related to MetaGPT, which is mentioned in choice 1..\n",
      "\u001b[0m这些文档介绍了一个名为MetaGPT的元编程框架，旨在增强基于大型语言模型的多智能体系统的问题解决能力。MetaGPT模拟软件公司代理，利用SOPs、角色专业化和信息共享机制，提高代码生成质量并取得先进性能。研究还涉及软件开发流程、人工智能模型评估以及多智能体协作等主题。\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"请使用中文简要概括文档\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f3cab28-09b3-4ba2-9073-f8847be2249f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mSelecting query engine 1: This choice is more relevant as it mentions retrieving specific context, which would be necessary to understand the research results on ablation..\n",
      "\u001b[0mAblation studies have shown that removing certain components or features from the system can have a significant impact on the overall performance. By systematically disabling or removing specific elements, researchers can evaluate the contribution and importance of each part to the system's functionality and effectiveness.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"请用告诉我关于ablation的研究结果?\")\n",
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
